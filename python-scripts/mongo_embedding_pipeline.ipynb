{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6efde6",
   "metadata": {},
   "source": [
    "# MongoDB Embedding Pipeline (Notebook)\n",
    "\n",
    "This notebook demonstrates how to: \n",
    "- Install required Python packages\n",
    "- Load the cleaned CSV (created by your preprocessing)\n",
    "- Import the `mongo_embedding_pipeline.py` script from `python-scripts/`\n",
    "- Generate embeddings for a small sample and upsert them into local MongoDB (mongodb://localhost:27017)\n",
    "- Run a sample similarity query\n",
    "\n",
    "Notes: run the cells in order. The notebook uses the pipeline implementation already added to `python-scripts/mongo_embedding_pipeline.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65662b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet sentence-transformers pymongo tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "731e9e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pymongo import MongoClient, ReplaceOne\n",
    "from typing import Optional\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "# External libs (ensure installed via pip in previous cell)\n",
    "from pymongo import MongoClient, ReplaceOne\n",
    "from typing import Optional\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800c5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: get mongo client (local by default)\n",
    "def get_mongo_client(uri: Optional[str] = None) -> MongoClient:\n",
    "    uri = uri or os.getenv('MONGO_URI', 'mongodb://localhost:27017')\n",
    "    return MongoClient(uri)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0625afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MongoNativePipeline:\n",
    "    def __init__(self, mongo_uri=None, db_name='cinebot', collection_name='movies_notebook'):\n",
    "        self.client = MongoClient(mongo_uri or os.getenv(\"MONGO_URI\", \"mongodb://localhost:27017\"))\n",
    "        self.db = self.client[db_name]\n",
    "        self.coll = self.db[collection_name]\n",
    "        self.model = None  # will load later\n",
    "\n",
    "    # ------------------------\n",
    "    def load_embedding_model(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        \"\"\"Load the embedding model (SentenceTransformers).\"\"\"\n",
    "        print(f\"ðŸ”„ Loading embedding model: {model_name}\")\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        print(\"âœ… Model loaded successfully\")\n",
    "\n",
    "    # ------------------------\n",
    "    def upsert_with_embeddings(self, df: pd.DataFrame, text_col=\"description\", id_col=\"id\", bulk_write_size=25):\n",
    "        \"\"\"Upsert movie docs with embeddings generated from the description field.\"\"\"\n",
    "        if self.model is None:\n",
    "            raise RuntimeError(\"âŒ Model not loaded. Call load_embedding_model() first.\")\n",
    "\n",
    "        ops = []\n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Upserting with embeddings\"):\n",
    "            text = str(row.get(text_col) or \"\")\n",
    "            movie_id = str(row[id_col])\n",
    "            embedding = self.model.encode(text)\n",
    "            if hasattr(embedding, \"tolist\"):\n",
    "                embedding = embedding.tolist()\n",
    "\n",
    "            doc = {\n",
    "                \"_id\": movie_id,\n",
    "                \"id\": movie_id,\n",
    "                \"title\": row.get(\"title\"),\n",
    "                \"year\": row.get(\"year\"),\n",
    "                \"description\": text,\n",
    "                \"embedding\": embedding,  # âœ… key part\n",
    "                \"genres\": parse_list(row.get(\"genres\")),\n",
    "                \"languages\": parse_list(row.get(\"languages\")),\n",
    "                \"directors\": parse_list(row.get(\"directors\")),\n",
    "                \"stars\": parse_list(row.get(\"stars\")),\n",
    "            }\n",
    "\n",
    "            ops.append(ReplaceOne({\"_id\": movie_id}, doc, upsert=True))\n",
    "\n",
    "            if len(ops) >= bulk_write_size:\n",
    "                self.coll.bulk_write(ops, ordered=False)\n",
    "                ops = []\n",
    "\n",
    "        if ops:\n",
    "            self.coll.bulk_write(ops, ordered=False)\n",
    "        print(f\"âœ… Upserted {len(df)} documents with embeddings into {self.coll.full_name}\")\n",
    "\n",
    "    # ------------------------\n",
    "    def create_vector_index(self, dim=384):\n",
    "        \"\"\"Create Atlas Vector Search index once.\"\"\"\n",
    "        from pymongo.errors import OperationFailure\n",
    "\n",
    "        index_name = \"movie_vector_index\"\n",
    "        index_definition = {\n",
    "            \"name\": index_name,\n",
    "            \"type\": \"vectorSearch\",\n",
    "            \"definition\": {\n",
    "                \"fields\": [\n",
    "                    {\"type\": \"vector\", \"path\": \"embedding\", \"numDimensions\": dim, \"similarity\": \"cosine\"}\n",
    "                ]\n",
    "            },\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            result = self.db.command(\"createSearchIndexes\", self.coll.name, indexes=[index_definition])\n",
    "            print(\"âœ… Vector search index created successfully:\", result)\n",
    "        except OperationFailure as e:\n",
    "            if \"already exists\" in str(e):\n",
    "                print(\"â„¹ï¸ Vector index already exists â€” skipping.\")\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    # ------------------------\n",
    "    def search_similar(self, query, top_k=5):\n",
    "        \"\"\"Run MongoDB-native $vectorSearch query.\"\"\"\n",
    "        if not self.model:\n",
    "            raise RuntimeError(\"âŒ Model not loaded. Run load_embedding_model() first.\")\n",
    "\n",
    "        query_vec = self.model.encode(query)\n",
    "        if hasattr(query_vec, \"tolist\"):\n",
    "            query_vec = query_vec.tolist()\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                \"$vectorSearch\": {\n",
    "                    \"index\": \"movie_vector_index\",  # âœ… match create_vector_index name\n",
    "                    \"path\": \"embedding\",\n",
    "                    \"queryVector\": query_vec,\n",
    "                    \"numCandidates\": 200,\n",
    "                    \"limit\": top_k,\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"$project\": {\n",
    "                    \"title\": 1,\n",
    "                    \"year\": 1,\n",
    "                    \"description\": 1,\n",
    "                    \"_id\": 0,\n",
    "                    \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "                }\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        results = list(self.coll.aggregate(pipeline))\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6362e0f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ac169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Full demo: load CSV, upsert a small sample, run search, and optionally run full upload ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b7118a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe shape: (63249, 25)\n"
     ]
    }
   ],
   "source": [
    "csv_path = Path('../cleaned_database/cleaned_final_dataset3.csv')\n",
    "if not csv_path.exists():\n",
    "    raise FileNotFoundError(f'Cleaned CSV not found at: {csv_path.resolve()}')\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded dataframe shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3361ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e23146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "MONGO_DB_NAME = os.getenv(\"MONGO_DB_NAME\", \"cinebot\")\n",
    "MONGO_COLLECTION = os.getenv(\"MONGO_COLLECTION\", \"movies_notebook\")\n",
    "\n",
    "print(\"âœ… Connected to:\", MONGO_URI.split('@')[-1])  # Just prints domain, not credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58fea749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upload first 5 rows (small sanity check)\n",
    "sample_df = df.head(5).copy()\n",
    "\n",
    "p.upsert_from_df(sample_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert your cleaned movie DataFrame\n",
    "upsert_with_embeddings_in_batches(p, df, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127e3b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create vector index once (only needed the first time)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m p\u001b[38;5;241m.\u001b[39mcreate_vector_index(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1536\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m, in \u001b[0;36mMongoNativePipeline.create_vector_index\u001b[1;34m(self, dim)\u001b[0m\n\u001b[0;32m     68\u001b[0m index_definition \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_name,\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorSearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     }\n\u001b[0;32m     81\u001b[0m }\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39mcommand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreateSearchIndexes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoll\u001b[38;5;241m.\u001b[39mname, indexes\u001b[38;5;241m=\u001b[39m[index_definition])\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Vector search index created successfully:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\_csot.py:119\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n\u001b[0;32m    118\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\database.py:930\u001b[0m, in \u001b[0;36mDatabase.command\u001b[1;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, comment, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m     read_preference \u001b[38;5;241m=\u001b[39m (session \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_txn_read_preference()) \u001b[38;5;129;01mor\u001b[39;00m ReadPreference\u001b[38;5;241m.\u001b[39mPRIMARY\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_conn_for_reads(read_preference, session, operation\u001b[38;5;241m=\u001b[39mcommand_name) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[0;32m    927\u001b[0m     connection,\n\u001b[0;32m    928\u001b[0m     read_preference,\n\u001b[0;32m    929\u001b[0m ):\n\u001b[1;32m--> 930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command(\n\u001b[0;32m    931\u001b[0m         connection,\n\u001b[0;32m    932\u001b[0m         command,\n\u001b[0;32m    933\u001b[0m         value,\n\u001b[0;32m    934\u001b[0m         check,\n\u001b[0;32m    935\u001b[0m         allowable_errors,\n\u001b[0;32m    936\u001b[0m         read_preference,\n\u001b[0;32m    937\u001b[0m         opts,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    938\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    940\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\database.py:770\u001b[0m, in \u001b[0;36mDatabase._command\u001b[1;34m(self, conn, command, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m command\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_tmp_session(session) \u001b[38;5;28;01mas\u001b[39;00m s:\n\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcommand(\n\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name,\n\u001b[0;32m    772\u001b[0m         command,\n\u001b[0;32m    773\u001b[0m         read_preference,\n\u001b[0;32m    774\u001b[0m         codec_options,\n\u001b[0;32m    775\u001b[0m         check,\n\u001b[0;32m    776\u001b[0m         allowable_errors,\n\u001b[0;32m    777\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n\u001b[0;32m    778\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[0;32m    779\u001b[0m         session\u001b[38;5;241m=\u001b[39ms,\n\u001b[0;32m    780\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n\u001b[0;32m    781\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\helpers.py:47\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynchronous\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\pool.py:536\u001b[0m, in \u001b[0;36mConnection.command\u001b[1;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m command(\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    538\u001b[0m         dbname,\n\u001b[0;32m    539\u001b[0m         spec,\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mongos,\n\u001b[0;32m    541\u001b[0m         read_preference,\n\u001b[0;32m    542\u001b[0m         codec_options,\n\u001b[0;32m    543\u001b[0m         session,\n\u001b[0;32m    544\u001b[0m         client,\n\u001b[0;32m    545\u001b[0m         check,\n\u001b[0;32m    546\u001b[0m         allowable_errors,\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress,\n\u001b[0;32m    548\u001b[0m         listeners,\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bson_size,\n\u001b[0;32m    550\u001b[0m         read_concern,\n\u001b[0;32m    551\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[0;32m    552\u001b[0m         collation\u001b[38;5;241m=\u001b[39mcollation,\n\u001b[0;32m    553\u001b[0m         compression_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression_context,\n\u001b[0;32m    554\u001b[0m         use_op_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_msg_enabled,\n\u001b[0;32m    555\u001b[0m         unacknowledged\u001b[38;5;241m=\u001b[39munacknowledged,\n\u001b[0;32m    556\u001b[0m         user_fields\u001b[38;5;241m=\u001b[39muser_fields,\n\u001b[0;32m    557\u001b[0m         exhaust_allowed\u001b[38;5;241m=\u001b[39mexhaust_allowed,\n\u001b[0;32m    558\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n\u001b[0;32m    559\u001b[0m     )\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\network.py:213\u001b[0m, in \u001b[0;36mcommand\u001b[1;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n\u001b[0;32m    211\u001b[0m             client\u001b[38;5;241m.\u001b[39m_process_response(response_doc, session)\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check:\n\u001b[1;32m--> 213\u001b[0m             helpers_shared\u001b[38;5;241m.\u001b[39m_check_command_response(\n\u001b[0;32m    214\u001b[0m                 response_doc,\n\u001b[0;32m    215\u001b[0m                 conn\u001b[38;5;241m.\u001b[39mmax_wire_version,\n\u001b[0;32m    216\u001b[0m                 allowable_errors,\n\u001b[0;32m    217\u001b[0m                 parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n\u001b[0;32m    218\u001b[0m             )\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    220\u001b[0m     duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\helpers_shared.py:247\u001b[0m, in \u001b[0;36m_check_command_response\u001b[1;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m43\u001b[39m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CursorNotFound(errmsg, code, response, max_wire_version)\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailure(errmsg, code, response, max_wire_version)\n",
      "\u001b[1;31mOperationFailure\u001b[0m: Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab9dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11737648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61580ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to: cinebot.cqwj7t2.mongodb.net/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3753df5",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mOperationFailure\u001b[0m                          Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create vector index once (only needed the first time)\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m p\u001b[38;5;241m.\u001b[39mcreate_vector_index(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1536\u001b[39m)\n",
      "\n",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m, in \u001b[0;36mMongoNativePipeline.create_vector_index\u001b[1;34m(self, dim)\u001b[0m\n",
      "\u001b[0;32m     68\u001b[0m index_definition \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: index_name,\n",
      "\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorSearch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m     80\u001b[0m     }\n",
      "\u001b[0;32m     81\u001b[0m }\n",
      "\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 84\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdb\u001b[38;5;241m.\u001b[39mcommand(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreateSearchIndexes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoll\u001b[38;5;241m.\u001b[39mname, indexes\u001b[38;5;241m=\u001b[39m[index_definition])\n",
      "\u001b[0;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Vector search index created successfully:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result)\n",
      "\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\_csot.py:119\u001b[0m, in \u001b[0;36mapply.<locals>.csot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _TimeoutContext(timeout):\n",
      "\u001b[0;32m    118\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\database.py:930\u001b[0m, in \u001b[0;36mDatabase.command\u001b[1;34m(self, command, value, check, allowable_errors, read_preference, codec_options, session, comment, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    925\u001b[0m     read_preference \u001b[38;5;241m=\u001b[39m (session \u001b[38;5;129;01mand\u001b[39;00m session\u001b[38;5;241m.\u001b[39m_txn_read_preference()) \u001b[38;5;129;01mor\u001b[39;00m ReadPreference\u001b[38;5;241m.\u001b[39mPRIMARY\n",
      "\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_conn_for_reads(read_preference, session, operation\u001b[38;5;241m=\u001b[39mcommand_name) \u001b[38;5;28;01mas\u001b[39;00m (\n",
      "\u001b[0;32m    927\u001b[0m     connection,\n",
      "\u001b[0;32m    928\u001b[0m     read_preference,\n",
      "\u001b[0;32m    929\u001b[0m ):\n",
      "\u001b[1;32m--> 930\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command(\n",
      "\u001b[0;32m    931\u001b[0m         connection,\n",
      "\u001b[0;32m    932\u001b[0m         command,\n",
      "\u001b[0;32m    933\u001b[0m         value,\n",
      "\u001b[0;32m    934\u001b[0m         check,\n",
      "\u001b[0;32m    935\u001b[0m         allowable_errors,\n",
      "\u001b[0;32m    936\u001b[0m         read_preference,\n",
      "\u001b[0;32m    937\u001b[0m         opts,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;32m    938\u001b[0m         session\u001b[38;5;241m=\u001b[39msession,\n",
      "\u001b[0;32m    939\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n",
      "\u001b[0;32m    940\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\database.py:770\u001b[0m, in \u001b[0;36mDatabase._command\u001b[1;34m(self, conn, command, value, check, allowable_errors, read_preference, codec_options, write_concern, parse_write_concern_error, session, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    768\u001b[0m command\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n",
      "\u001b[0;32m    769\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39m_tmp_session(session) \u001b[38;5;28;01mas\u001b[39;00m s:\n",
      "\u001b[1;32m--> 770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mcommand(\n",
      "\u001b[0;32m    771\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name,\n",
      "\u001b[0;32m    772\u001b[0m         command,\n",
      "\u001b[0;32m    773\u001b[0m         read_preference,\n",
      "\u001b[0;32m    774\u001b[0m         codec_options,\n",
      "\u001b[0;32m    775\u001b[0m         check,\n",
      "\u001b[0;32m    776\u001b[0m         allowable_errors,\n",
      "\u001b[0;32m    777\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n",
      "\u001b[0;32m    778\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n",
      "\u001b[0;32m    779\u001b[0m         session\u001b[38;5;241m=\u001b[39ms,\n",
      "\u001b[0;32m    780\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client,\n",
      "\u001b[0;32m    781\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\helpers.py:47\u001b[0m, in \u001b[0;36m_handle_reauth.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymongo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msynchronous\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n",
      "\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OperationFailure \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m no_reauth:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\pool.py:536\u001b[0m, in \u001b[0;36mConnection.command\u001b[1;34m(self, dbname, spec, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n",
      "\u001b[0;32m    534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_not_writable(unacknowledged)\n",
      "\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m command(\n",
      "\u001b[0;32m    537\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m    538\u001b[0m         dbname,\n",
      "\u001b[0;32m    539\u001b[0m         spec,\n",
      "\u001b[0;32m    540\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_mongos,\n",
      "\u001b[0;32m    541\u001b[0m         read_preference,\n",
      "\u001b[0;32m    542\u001b[0m         codec_options,\n",
      "\u001b[0;32m    543\u001b[0m         session,\n",
      "\u001b[0;32m    544\u001b[0m         client,\n",
      "\u001b[0;32m    545\u001b[0m         check,\n",
      "\u001b[0;32m    546\u001b[0m         allowable_errors,\n",
      "\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddress,\n",
      "\u001b[0;32m    548\u001b[0m         listeners,\n",
      "\u001b[0;32m    549\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_bson_size,\n",
      "\u001b[0;32m    550\u001b[0m         read_concern,\n",
      "\u001b[0;32m    551\u001b[0m         parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n",
      "\u001b[0;32m    552\u001b[0m         collation\u001b[38;5;241m=\u001b[39mcollation,\n",
      "\u001b[0;32m    553\u001b[0m         compression_ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression_context,\n",
      "\u001b[0;32m    554\u001b[0m         use_op_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mop_msg_enabled,\n",
      "\u001b[0;32m    555\u001b[0m         unacknowledged\u001b[38;5;241m=\u001b[39munacknowledged,\n",
      "\u001b[0;32m    556\u001b[0m         user_fields\u001b[38;5;241m=\u001b[39muser_fields,\n",
      "\u001b[0;32m    557\u001b[0m         exhaust_allowed\u001b[38;5;241m=\u001b[39mexhaust_allowed,\n",
      "\u001b[0;32m    558\u001b[0m         write_concern\u001b[38;5;241m=\u001b[39mwrite_concern,\n",
      "\u001b[0;32m    559\u001b[0m     )\n",
      "\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (OperationFailure, NotPrimaryError):\n",
      "\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\synchronous\\network.py:213\u001b[0m, in \u001b[0;36mcommand\u001b[1;34m(conn, dbname, spec, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed, write_concern)\u001b[0m\n",
      "\u001b[0;32m    211\u001b[0m             client\u001b[38;5;241m.\u001b[39m_process_response(response_doc, session)\n",
      "\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m check:\n",
      "\u001b[1;32m--> 213\u001b[0m             helpers_shared\u001b[38;5;241m.\u001b[39m_check_command_response(\n",
      "\u001b[0;32m    214\u001b[0m                 response_doc,\n",
      "\u001b[0;32m    215\u001b[0m                 conn\u001b[38;5;241m.\u001b[39mmax_wire_version,\n",
      "\u001b[0;32m    216\u001b[0m                 allowable_errors,\n",
      "\u001b[0;32m    217\u001b[0m                 parse_write_concern_error\u001b[38;5;241m=\u001b[39mparse_write_concern_error,\n",
      "\u001b[0;32m    218\u001b[0m             )\n",
      "\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;32m    220\u001b[0m     duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\pymongo\\helpers_shared.py:247\u001b[0m, in \u001b[0;36m_check_command_response\u001b[1;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n",
      "\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m43\u001b[39m:\n",
      "\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CursorNotFound(errmsg, code, response, max_wire_version)\n",
      "\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationFailure(errmsg, code, response, max_wire_version)\n",
      "\n",
      "\u001b[1;31mOperationFailure\u001b[0m: Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}"
     ]
    }
   ],
   "source": [
    "# Create vector index once (only needed the first time)\n",
    "p.create_vector_index(dim=1536)  # use your providerâ€™s embedding dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f5d27b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MongoNativePipeline' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m p \u001b[38;5;241m=\u001b[39m MongoNativePipeline(mongo_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmongodb://localhost:27017\u001b[39m\u001b[38;5;124m'\u001b[39m, db_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcinebot\u001b[39m\u001b[38;5;124m'\u001b[39m, collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovies_notebook\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Lazy-load model (this may download model weights the first time)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loaded. Embedding dim (if available):\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_sentence_embedding_dimension\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MongoNativePipeline' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51872ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings shape: (5, 384)\n",
      "First embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for a small sample (first 5 rows) to validate everything works\n",
    "sample = df.head(5).copy()\n",
    "docs = sample['docs'].fillna('').astype(str).tolist()\n",
    "embs = p.generate_embeddings(docs, batch_size=8)\n",
    "print('Generated embeddings shape:', embs.shape)\n",
    "print('First embedding length:', len(embs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924023ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected embedding dimension: 384\n",
      "Upserted rows 1-5: upserted=0, modified=0\n",
      "Could not create vector search index (server may not support it): Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}\n",
      "Processed 5/5 rows\n",
      "All batches processed.\n",
      "Upsert completed for sample collection: cinebot.movies_notebook\n",
      "Upserted rows 1-5: upserted=0, modified=0\n",
      "Could not create vector search index (server may not support it): Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs., full error: {'ok': 0.0, 'errmsg': 'Using Atlas Search Database Commands and the $listSearchIndexes aggregation stage requires additional configuration. Please connect to Atlas or an AtlasCLI local deployment to enable. For more information on how to connect, see https://dochub.mongodb.org/core/atlas-cli-deploy-local-reqs.', 'code': 31082, 'codeName': 'SearchNotEnabled'}\n",
      "Processed 5/5 rows\n",
      "All batches processed.\n",
      "Upsert completed for sample collection: cinebot.movies_notebook\n"
     ]
    }
   ],
   "source": [
    "# Upsert the small sample into MongoDB (safe to re-run)\n",
    "p.upsert_from_df(sample, csv_id_col='id', batch_size=5)\n",
    "print('Upsert completed for sample collection:', p.coll.full_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75636d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>similarity</th>\n",
       "      <th>description_snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tt29195117</td>\n",
       "      <td>Justice League: Crisis on Infinite Earths - Pa...</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.458105</td>\n",
       "      <td>The Anti-Monitor, the Monitor's evil counterpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tt6263850</td>\n",
       "      <td>Deadpool &amp; Wolverine</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.455439</td>\n",
       "      <td>Deadpool is offered a place in the Marvel Cine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0347167</td>\n",
       "      <td>The Hero: Love Story of a Spy</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.428149</td>\n",
       "      <td>Arun is an Indian undercover agent enlisted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tt19500164</td>\n",
       "      <td>Nimona</td>\n",
       "      <td>2023</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.411302</td>\n",
       "      <td>When a knight in a futuristic medieval world i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>tt0123248</td>\n",
       "      <td>Run Chrissie Run!</td>\n",
       "      <td>1984</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.409940</td>\n",
       "      <td>The action moves along quickly in this made-fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank          id                                              title  year  \\\n",
       "0     1  tt29195117  Justice League: Crisis on Infinite Earths - Pa...  2024   \n",
       "1     2   tt6263850                               Deadpool & Wolverine  2024   \n",
       "2     3   tt0347167                      The Hero: Love Story of a Spy  2003   \n",
       "3     4  tt19500164                                             Nimona  2023   \n",
       "4     5   tt0123248                                  Run Chrissie Run!  1984   \n",
       "\n",
       "   rating  similarity                                description_snippet  \n",
       "0     6.2    0.458105  The Anti-Monitor, the Monitor's evil counterpa...  \n",
       "1     7.6    0.455439  Deadpool is offered a place in the Marvel Cine...  \n",
       "2     5.5    0.428149  Arun is an Indian undercover agent enlisted to...  \n",
       "3     7.5    0.411302  When a knight in a futuristic medieval world i...  \n",
       "4     5.5    0.409940  The action moves along quickly in this made-fo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>rating</th>\n",
       "      <th>similarity</th>\n",
       "      <th>description_snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>tt29195117</td>\n",
       "      <td>Justice League: Crisis on Infinite Earths - Pa...</td>\n",
       "      <td>2024</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.458105</td>\n",
       "      <td>The Anti-Monitor, the Monitor's evil counterpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>tt6263850</td>\n",
       "      <td>Deadpool &amp; Wolverine</td>\n",
       "      <td>2024</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.455439</td>\n",
       "      <td>Deadpool is offered a place in the Marvel Cine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0347167</td>\n",
       "      <td>The Hero: Love Story of a Spy</td>\n",
       "      <td>2003</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.428149</td>\n",
       "      <td>Arun is an Indian undercover agent enlisted to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>tt19500164</td>\n",
       "      <td>Nimona</td>\n",
       "      <td>2023</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.411302</td>\n",
       "      <td>When a knight in a futuristic medieval world i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>tt0123248</td>\n",
       "      <td>Run Chrissie Run!</td>\n",
       "      <td>1984</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.409940</td>\n",
       "      <td>The action moves along quickly in this made-fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank          id                                              title  year  \\\n",
       "0     1  tt29195117  Justice League: Crisis on Infinite Earths - Pa...  2024   \n",
       "1     2   tt6263850                               Deadpool & Wolverine  2024   \n",
       "2     3   tt0347167                      The Hero: Love Story of a Spy  2003   \n",
       "3     4  tt19500164                                             Nimona  2023   \n",
       "4     5   tt0123248                                  Run Chrissie Run!  1984   \n",
       "\n",
       "   rating  similarity                                description_snippet  \n",
       "0     6.2    0.458105  The Anti-Monitor, the Monitor's evil counterpa...  \n",
       "1     7.6    0.455439  Deadpool is offered a place in the Marvel Cine...  \n",
       "2     5.5    0.428149  Arun is an Indian undercover agent enlisted to...  \n",
       "3     7.5    0.411302  When a knight in a futuristic medieval world i...  \n",
       "4     5.5    0.409940  The action moves along quickly in this made-fo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Readable list:\n",
      "1. Justice League: Crisis on Infinite Earths - Part One (id=tt29195117) - similarity=0.4581\n",
      "    The Anti-Monitor, the Monitor's evil counterpart, is released into the DC Multiverse and begins to destroy the different Earths that compose it. The Monitor attempts to recruit heroes from across the \n",
      "2. Deadpool & Wolverine (id=tt6263850) - similarity=0.4554\n",
      "    Deadpool is offered a place in the Marvel Cinematic Universe by the Time Variance Authority, but instead recruits a variant of Wolverine to save his universe from extinction.\n",
      "3. The Hero: Love Story of a Spy (id=tt0347167) - similarity=0.4281\n",
      "    Arun is an Indian undercover agent enlisted to stop ISI chief Ishaq Khan. The village girl Reshma helps him but endangers her own life.\n",
      "4. Nimona (id=tt19500164) - similarity=0.4113\n",
      "    When a knight in a futuristic medieval world is framed for a crime he didn't commit, the only one who can help him prove his innocence is Nimona -- a mischievous teen who happens to be a shapeshifting\n",
      "5. Run Chrissie Run! (id=tt0123248) - similarity=0.4099\n",
      "    The action moves along quickly in this made-for-television drama about Eve, an ex-terrorist from Germany who is forced to escape to Australia with her teenage daughter Chrissie when she is sought by R\n"
     ]
    }
   ],
   "source": [
    "# Run a sample similarity search\n",
    "results = p.search_similar('action movie with superheroes', top_k=5)\n",
    "print('Top results:')\n",
    "if not results:\n",
    "    print('No results returned. Possible reasons: no documents in collection, embeddings missing, or text filter matched nothing.')\n",
    "else:\n",
    "    import pandas as _pd\n",
    "    rows = []\n",
    "    for rank, r in enumerate(results, start=1):\n",
    "        rows.append({\n",
    "            'rank': rank,\n",
    "            'id': r.get('_id'),\n",
    "            'title': r.get('title'),\n",
    "            'year': r.get('year'),\n",
    "            'rating': r.get('rating'),\n",
    "            'similarity': r.get('similarity'),\n",
    "            'description_snippet': (r.get('description') or '')[:200]\n",
    "        })\n",
    "    df_results = _pd.DataFrame(rows)\n",
    "    display(df_results)\n",
    "    print('\\nReadable list:')\n",
    "    for _, row in df_results.iterrows():\n",
    "        print(f\"{int(row['rank'])}. {row['title']} (id={row['id']}) - similarity={row['similarity']:.4f}\")\n",
    "        print('   ', row['description_snippet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a1d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating collection: cinebot.movies_notebook\n",
      "Collection cleared. Starting full upload...\n",
      "Detected embedding dimension: 384\n",
      "Collection cleared. Starting full upload...\n",
      "Detected embedding dimension: 384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncating collection: cinebot.movies_notebook\n",
      "Collection cleared. Starting full upload...\n",
      "Detected embedding dimension: 384\n",
      "Collection cleared. Starting full upload...\n",
      "Detected embedding dimension: 384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCollection cleared. Starting full upload...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Choose a batch size appropriate for your machine\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     p\u001b[38;5;241m.\u001b[39mupsert_from_df(df, csv_id_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFull upload complete.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m, in \u001b[0;36mMongoEmbeddingPipeline.upsert_from_df\u001b[1;34m(self, df, csv_path, csv_id_col, batch_size, bulk_write_size, create_vector_index, chunksize)\u001b[0m\n\u001b[0;32m    131\u001b[0m sub_docs \u001b[38;5;241m=\u001b[39m docs[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mmin\u001b[39m(batch_size, \u001b[38;5;241m32\u001b[39m)]\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 133\u001b[0m     sub_embs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_embeddings(sub_docs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(sub_docs))\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError generating embeddings for sub-batch, retrying smaller batch:\u001b[39m\u001b[38;5;124m'\u001b[39m, e)\n",
      "Cell \u001b[1;32mIn[3], line 64\u001b[0m, in \u001b[0;36mMongoEmbeddingPipeline.generate_embeddings\u001b[1;34m(self, docs, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_model()\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Use a conservative default batch size to limit memory use\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m embs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(docs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, convert_to_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embs\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:685\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 685\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    687\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:758\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    756\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[0;32m    757\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs)\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:442\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features, **kwargs)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[0;32m    436\u001b[0m trans_features \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    437\u001b[0m     key: value\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    440\u001b[0m }\n\u001b[1;32m--> 442\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    443\u001b[0m token_embeddings \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    444\u001b[0m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m token_embeddings\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1144\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1144\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1145\u001b[0m     embedding_output,\n\u001b[0;32m   1146\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1147\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1148\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[0;32m   1149\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[0;32m   1150\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[0;32m   1151\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[0;32m   1152\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1153\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1154\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1155\u001b[0m )\n\u001b[0;32m   1156\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1157\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    696\u001b[0m         hidden_states,\n\u001b[0;32m    697\u001b[0m         attention_mask,\n\u001b[0;32m    698\u001b[0m         layer_head_mask,\n\u001b[0;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[0;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[0;32m    701\u001b[0m         past_key_value,\n\u001b[0;32m    702\u001b[0m         output_attentions,\n\u001b[0;32m    703\u001b[0m     )\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[0;32m    629\u001b[0m )\n\u001b[0;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:539\u001b[0m, in \u001b[0;36mBertIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 539\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m    540\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\rohan\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Truncate & run full pipeline (CAUTION)\n",
    "# Set confirm_run_full = True to actually delete and upload entire dataset\n",
    "confirm_run_full = True  # change to True when you are ready\n",
    "if confirm_run_full:\n",
    "    print('Truncating collection:', p.coll.full_name)\n",
    "    p.coll.delete_many({})\n",
    "    print('Collection cleared. Starting full upload...')\n",
    "    # Choose a batch size appropriate for your machine\n",
    "    p.upsert_from_df(df, csv_id_col='id', batch_size=128)\n",
    "    print('Full upload complete.')\n",
    "else:\n",
    "    print('confirm_run_full is False; full upload skipped. Set confirm_run_full = True to run it.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d071600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed MongoDB client\n"
     ]
    }
   ],
   "source": [
    "# Cleanup: close the MongoDB client when done\n",
    "p.client.close()\n",
    "print('Closed MongoDB client')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
